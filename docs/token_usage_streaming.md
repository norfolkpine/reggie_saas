# Tracking Token Usage in Streaming Responses

This project now exposes **token-usage metrics** (input, output and total tokens) for every streamed chat response. The information is delivered as additional **Server-Sent Event (SSE)** debug messages once the stream has finished.

---

## When are the metrics sent?

1.  The client sends a `POST /reggie/api/v1/chat/stream/` request with `stream=true`.
2.  `StreamAgentConsumer` builds the `Agent` and starts streaming `agent.run()` chunks.
3.  After the final chunk is sent, the consumer reads `agent.run_response.metrics` provided by the AGNO framework.  
    • `input_tokens`  – tokens in the prompt  
    • `output_tokens` – tokens generated by the model  
    • `total_tokens`  – sum of the above (some providers already include this)
4.  Three extra **debug events** are emitted:

```text
data: {"debug": "Prompt tokens: 931"}

data: {"debug": "Completion tokens: 397"}

data: {"debug": "Total tokens: 1416"}

# Example when multiple model calls were made
data: {"debug": "Prompt tokens: [931, 1019, 1457]"}

data: {"debug": "Completion tokens: [10, 397, 353]"}

data: {"debug": "Total tokens: [941, 1416, 1810]"}
```

A final `[DONE]` message closes the stream as usual.

> If `agent.run_response.metrics` is missing (e.g. unsupported LLM) the consumer silently drops the events and the values default to `0`.

---

## Consuming the metrics on the front-end

Because they are regular SSE messages you can capture them the same way you already handle normal events:

```javascript
const source = new EventSource(url);
source.onmessage = (event) => {
  const data = JSON.parse(event.data);
  if (data.debug?.startsWith('Prompt tokens')) {
    console.log('Prompt:', data.debug);
  } else if (data.debug?.startsWith('Completion tokens')) {
    console.log('Completion:', data.debug);
  } else if (data.debug?.startsWith('Total tokens')) {
    console.log('Total:', data.debug);
  } else {
    // regular content / other debug lines
  }
};
```

Store the numbers per user/session to implement quotas, billing, or usage analytics.

---

## Implementation details (backend)

* **File:** `apps/reggie/consumers.py`
* **Key logic:** after streaming loop, this snippet runs:

```python
if getattr(agent, "run_response", None) and getattr(agent.run_response, "metrics", None):
    metrics = agent.run_response.metrics
    prompt_tokens = metrics.get("input_tokens", 0)
    completion_tokens = metrics.get("output_tokens", 0)
    total_tokens = metrics.get("total_tokens", prompt_tokens + completion_tokens)
    for label, value in (
        ("Prompt", prompt_tokens),
        ("Completion", completion_tokens),
        ("Total", total_tokens),
    ):
        await self.send_body(
            f"data: {{\"debug\": f'{label} tokens: {value}'}}\n\n".encode(),
            more_body=True,
        )
```

* No model-specific helpers are needed—AGNO populates `metrics` automatically for OpenAI/Anthropic-style providers.

---

## FAQ

**Q: Why do I sometimes see an *array* of numbers (e.g. `[931, 1019, 1457]`) instead of a single integer?**  
AGNO stores the token usage for **every individual model call** that happened during the request. Most queries need exactly one call so you get a scalar.  
If the agent had to chain multiple calls (tool invocation, function-calling, long answer split into several completions, etc.) the metrics become a list where each entry is the tokens for that sub-call in chronological order.  
Each *position* in the three arrays refers to the **same model call**:

* index 0 → first call (Prompt = 1843, Completion = 50, Total = 1893)
* index 1 → second call (1844 + 309 = 2153)
* index 2 → third call (1434 + 10 = 1444)
* index 3 → fourth call (1453 + 25 = 1478)

So you can pair the numbers across the arrays by their index. The `Total tokens` element is simply `Prompt + Completion` for that call.

**Q: Why are my numbers `[0, 0, 0]`?**  
Your LLM provider may not return usage metadata. Check AGNO release notes or switch to a provider that supports token usage.

**Q: Will this impact latency?**  
Negligibly—the metrics are read from the already-available response object and sent as three small SSE events.

**Q: Can I disable these debug events?**  
Set `debug_mode=False` on the agent or filter them client-side.
